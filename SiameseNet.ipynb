{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GRID K520 (CNMeM is disabled, CuDNN not available)\n",
      "/home/ubuntu/anaconda/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from new_SiameseNet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting CIFAR10 data...\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "print 'Getting CIFAR10 data...'\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "\n",
    "x_train, y_train = data['X_train'], data['y_train']\n",
    "x_val,   y_val   = data['X_val'],   data['y_val']\n",
    "\n",
    "N = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed a SiameseNet.\n",
      "Successfully compiled the SiameseNet.\n"
     ]
    }
   ],
   "source": [
    "# Specify structure of Siamese part of SiameseNet\n",
    "# This part needs to be improved. I'm kind of just using random layers.\n",
    "init = 'glorot_uniform'\n",
    "in_shp = (3,32,32)\n",
    "seq = Sequential()\n",
    "seq.add(BatchNormalization(epsilon=1e-7,\n",
    "                            mode=0,\n",
    "                            axis=1,\n",
    "                            momentum=0.9,\n",
    "                            weights=None,\n",
    "                            input_shape=in_shp))\n",
    "#seq.add(Flatten())\n",
    "#seq.add(Dense(128, activation='relu'))\n",
    "#seq.add(Dropout(0.1))\n",
    "#seq.add(Dense(128, activation='relu'))\n",
    "#seq.add(Dropout(0.1))\n",
    "for _ in range(1):\n",
    "    seq.add(Convolution2D(10, 3, 3, init=init, border_mode='same'))\n",
    "    seq.add(Activation('relu'))\n",
    "#seq.add(Dense(128, activation='relu'))\n",
    "seq.add(Flatten())\n",
    "seq.add(Dense(128))\n",
    "layers = seq\n",
    "\n",
    "sn = SiameseNet(layers, input_shape=(3, 32, 32), verbose=True)\n",
    "sn.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Done generating data\n",
      "Generating data...\n",
      "Done generating data\n",
      "Train on 19588 samples, validate on 2060 samples\n",
      "Epoch 1/2\n",
      " 7040/19588 [=========>....................] - ETA: 6s - loss: 0.2731"
     ]
    }
   ],
   "source": [
    "def _train_sn(sn, x_train, y_train, x_val, y_val, filepath):\n",
    "    d_val = invert_dataset(x_val,  y_val)\n",
    "    d_train = invert_dataset(x_train,  y_train)\n",
    "    num_ep = 2\n",
    "    history = sn.fit(*generate_data(d_train, examples_per_image=1), \n",
    "           validation_data=generate_data(d_val, examples_per_image=5),\n",
    "           nb_epoch=num_ep) #, validation_data=generate_data(x_val, y_val))\n",
    "    return history\n",
    "\n",
    "history = _train_sn(sn, x_train, y_train, x_val, y_val, filepath='weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loss = sn.evaluate(*generate_data(d_val, examples_per_image=5))\n",
    "val_x_dat, val_y_dat = generate_data(d_val, examples_per_image=5)\n",
    "prediction = sn.predict(val_x_dat)[SiameseNet.OUTPUT]\n",
    "\n",
    "ret_preds = prediction\n",
    "max_d = np.max(ret_preds)\n",
    "min_d = np.min(ret_preds)\n",
    "\n",
    "print max_d\n",
    "print min_d\n",
    "\n",
    "#thresh = (max_d + min_d) / 2.0\n",
    "#preds = [0,0]\n",
    "#for i,p in enumerate(prediction):\n",
    "#    if ret_preds[i] > thresh:\n",
    "#        preds[1] += 1\n",
    "#    else:\n",
    "#        preds[0] += 1\n",
    "#print preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
