{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GRID K520 (CNMeM is disabled, CuDNN not available)\n",
      "/home/ubuntu/anaconda/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from new_SiameseNet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting CIFAR10 data...\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "print 'Getting CIFAR10 data...'\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "\n",
    "x_train, y_train = data['X_train'], data['y_train']\n",
    "x_val,   y_val   = data['X_val'],   data['y_val']\n",
    "\n",
    "N = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed a SiameseNet.\n",
      "Successfully compiled the SiameseNet.\n"
     ]
    }
   ],
   "source": [
    "# Specify structure of Siamese part of SiameseNet\n",
    "# This part needs to be improved. I'm kind of just using random layers.\n",
    "init = 'glorot_uniform'\n",
    "in_shp = (3,32,32)\n",
    "seq = Sequential()\n",
    "seq.add(BatchNormalization(epsilon=1e-7,\n",
    "                            mode=0,\n",
    "                            axis=1,\n",
    "                            momentum=0.9,\n",
    "                            weights=None,\n",
    "                            input_shape=in_shp))\n",
    "#seq.add(Flatten())\n",
    "#seq.add(Dense(128, activation='relu'))\n",
    "#seq.add(Dropout(0.1))\n",
    "#seq.add(Dense(128, activation='relu'))\n",
    "#seq.add(Dropout(0.1))\n",
    "for _ in range(1):\n",
    "    seq.add(Convolution2D(10, 3, 3, init=init, border_mode='same'))\n",
    "    seq.add(Activation('relu'))\n",
    "#seq.add(Dense(128, activation='relu'))\n",
    "seq.add(Flatten())\n",
    "seq.add(Dense(128))\n",
    "layers = seq\n",
    "\n",
    "sn = SiameseNet(layers, input_shape=(3, 32, 32), verbose=True)\n",
    "sn.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 97600 samples, validate on 1540 samples\n",
      "Epoch 1/2\n",
      "97600/97600 [==============================] - 54s - loss: 0.9045 - val_loss: 0.2265\n",
      "Epoch 2/2\n",
      "97600/97600 [==============================] - 54s - loss: 0.2272 - val_loss: 0.2242\n",
      "Done training the SiameseNet.\n"
     ]
    }
   ],
   "source": [
    "def _train_sn(sn, x_train, y_train, x_val, y_val, filepath):\n",
    "    d_val = invert_dataset(x_val,  y_val)\n",
    "    d_train = invert_dataset(x_train,  y_train)\n",
    "    num_ep = 2\n",
    "    history = sn.fit(*generate_data(x_train, d_train), \n",
    "           validation_data=generate_data(x_val, d_val),\n",
    "           nb_epoch=num_ep)\n",
    "    return history\n",
    "\n",
    "history = _train_sn(sn, x_train, y_train, x_val, y_val, filepath='weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities are {'output': array([[ 0.73530477],\n",
      "       [ 0.50071985],\n",
      "       [ 0.28664848],\n",
      "       ..., \n",
      "       [ 0.70548493],\n",
      "       [ 0.5286566 ],\n",
      "       [ 0.5686509 ]])}\n",
      "1.52992796898\n",
      "0.235659629107\n"
     ]
    }
   ],
   "source": [
    "#loss = sn.evaluate(*generate_data(d_val, examples_per_image=5))\n",
    "d_val = invert_dataset(x_val,  y_val)\n",
    "val_x_dat, val_y_dat = generate_data(x_val, d_val)\n",
    "prediction = sn.predict(val_x_dat)[SiameseNet.OUTPUT]\n",
    "\n",
    "ret_preds = prediction\n",
    "max_d = np.max(ret_preds)\n",
    "min_d = np.min(ret_preds)\n",
    "\n",
    "print max_d\n",
    "print min_d\n",
    "\n",
    "#thresh = (max_d + min_d) / 2.0\n",
    "#preds = [0,0]\n",
    "#for i,p in enumerate(prediction):\n",
    "#    if ret_preds[i] > thresh:\n",
    "#        preds[1] += 1\n",
    "#    else:\n",
    "#        preds[0] += 1\n",
    "#print preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.90445654848559953, 0.22720627847265024], 'val_loss': [0.2265235638850695, 0.22422721416919261], 'batch': [762, 762], 'size': [64, 64]}\n"
     ]
    }
   ],
   "source": [
    "print history.history\n",
    "l = history.history['loss']\n",
    "val_l = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(l, label='Training Loss')\n",
    "plt.title('Siamese Network Training/Validation Loss vs. Epochs')\n",
    "plt.plot(val_l, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('siam_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity(sn, x1, x2):\n",
    "    x = [x1, x2]\n",
    "    prediction = sn.predict(x, batch_size=1)\n",
    "    return prediction['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
